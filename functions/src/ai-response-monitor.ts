/**
 * AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ç›£è¦–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
 *
 * Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã€å“è³ªå•é¡Œã‚’æ—©æœŸæ¤œå‡ºã™ã‚‹ã€‚
 * BUG-022ï¼ˆthinkingãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ï¼‰ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã€‚
 */

/**
 * AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä½¿ç”¨é‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
 */
export interface UsageMetrics {
  promptTokenCount?: number;
  thoughtsTokenCount?: number;
  candidatesTokenCount?: number;
  totalTokenCount?: number;
}

/**
 * AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯çµæœ
 */
export interface HealthCheckResult {
  isHealthy: boolean;
  issues: string[];
  metrics: {
    thinkingRatio: number | null;  // æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³æ¯”ç‡
    outputRatio: number | null;    // å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ¯”ç‡
    finishReason: string;
    responseLength: number;
  };
}

/**
 * finishReasonã®èª¬æ˜
 */
const FINISH_REASON_DESCRIPTIONS: Record<string, string> = {
  'STOP': 'æ­£å¸¸å®Œäº†',
  'MAX_TOKENS': 'ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™åˆ°é” - maxOutputTokensã®å¢—åŠ ã‚’æ¤œè¨',
  'SAFETY': 'å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦‹ç›´ã—ã‚’æ¤œè¨',
  'RECITATION': 'å¼•ç”¨åˆ¶é™ - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦‹ç›´ã—ã‚’æ¤œè¨',
  'OTHER': 'ä¸æ˜ãªç†ç”± - è©³ç´°èª¿æŸ»ãŒå¿…è¦',
};

/**
 * AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
 *
 * ä»¥ä¸‹ã®å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º:
 * 1. æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ãŒtotalã®90%ä»¥ä¸Šï¼ˆBUG-022ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
 * 2. å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ãŒç•°å¸¸ã«å°‘ãªã„
 * 3. finishReasonãŒSTOPä»¥å¤–
 * 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ¬æ–‡ãŒç©º
 */
export function checkResponseHealth(
  response: {
    text?: string;
    candidates?: Array<{ finishReason?: string }>;
    usageMetadata?: UsageMetrics;
  },
  operationName: string
): HealthCheckResult {
  const issues: string[] = [];
  const usageMetadata = response.usageMetadata || {};
  const finishReason = response.candidates?.[0]?.finishReason || 'UNKNOWN';
  const responseLength = response.text?.length || 0;

  // æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³æ¯”ç‡ã‚’è¨ˆç®—
  let thinkingRatio: number | null = null;
  let outputRatio: number | null = null;

  if (usageMetadata.totalTokenCount && usageMetadata.totalTokenCount > 0) {
    if (usageMetadata.thoughtsTokenCount !== undefined) {
      thinkingRatio = usageMetadata.thoughtsTokenCount / usageMetadata.totalTokenCount;
    }
    if (usageMetadata.candidatesTokenCount !== undefined) {
      outputRatio = usageMetadata.candidatesTokenCount / usageMetadata.totalTokenCount;
    }
  }

  // å•é¡Œæ¤œå‡º

  // 1. æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³éå‰°æ¶ˆè²»ï¼ˆBUG-022ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
  if (thinkingRatio !== null && thinkingRatio > 0.90) {
    issues.push(
      `âš ï¸ æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³éå‰°æ¶ˆè²»: ${(thinkingRatio * 100).toFixed(1)}% ` +
      `(${usageMetadata.thoughtsTokenCount}/${usageMetadata.totalTokenCount}) - ` +
      `BUG-022ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯èƒ½æ€§`
    );
  }

  // 2. å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ãŒç•°å¸¸ã«å°‘ãªã„
  if (outputRatio !== null && outputRatio < 0.05 && responseLength > 0) {
    issues.push(
      `âš ï¸ å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ¯”ç‡ãŒä½ã„: ${(outputRatio * 100).toFixed(1)}% - ` +
      `æ€è€ƒã«å¤šãã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã—ã¦ã„ã‚‹å¯èƒ½æ€§`
    );
  }

  // 3. finishReasonãŒæ­£å¸¸ã§ãªã„
  if (finishReason !== 'STOP') {
    const description = FINISH_REASON_DESCRIPTIONS[finishReason] || 'ä¸æ˜ãªçµ‚äº†ç†ç”±';
    issues.push(`âš ï¸ çµ‚äº†ç†ç”±: ${finishReason} - ${description}`);
  }

  // 4. ãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ¬æ–‡ãŒç©º
  if (responseLength === 0) {
    issues.push('âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ¬æ–‡ãŒç©ºã§ã™');
  }

  // 5. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç•°å¸¸ã«çŸ­ã„ï¼ˆJSONã¨ã—ã¦è§£æä¸èƒ½ã®å¯èƒ½æ€§ï¼‰
  if (responseLength > 0 && responseLength < 100) {
    issues.push(`âš ï¸ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒéå¸¸ã«çŸ­ã„: ${responseLength}æ–‡å­—`);
  }

  const isHealthy = issues.length === 0;

  // ãƒ­ã‚°å‡ºåŠ›
  if (!isHealthy) {
    console.warn(`ğŸ” [${operationName}] AIãƒ¬ã‚¹ãƒãƒ³ã‚¹å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯: å•é¡Œæ¤œå‡º`);
    for (const issue of issues) {
      console.warn(`   ${issue}`);
    }
  } else {
    console.log(`âœ… [${operationName}] AIãƒ¬ã‚¹ãƒãƒ³ã‚¹å¥å…¨æ€§: OK`);
  }

  return {
    isHealthy,
    issues,
    metrics: {
      thinkingRatio,
      outputRatio,
      finishReason,
      responseLength,
    },
  };
}

/**
 * AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
 */
export function logDetailedResponseMetrics(
  response: {
    text?: string;
    candidates?: Array<{ finishReason?: string }>;
    usageMetadata?: UsageMetrics;
  },
  operationName: string,
  processingTimeMs: number
): void {
  const usageMetadata = response.usageMetadata || {};
  const finishReason = response.candidates?.[0]?.finishReason || 'N/A';
  const responseLength = response.text?.length || 0;

  console.log(`ğŸ“Š [${operationName}] AI Response Details:`, {
    finishReason,
    responseLength,
    processingTimeMs,
    usageMetadata: {
      promptTokenCount: usageMetadata.promptTokenCount || 'N/A',
      thoughtsTokenCount: usageMetadata.thoughtsTokenCount || 'N/A',
      candidatesTokenCount: usageMetadata.candidatesTokenCount || 'N/A',
      totalTokenCount: usageMetadata.totalTokenCount || 'N/A',
    },
  });

  // å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
  checkResponseHealth(response, operationName);
}

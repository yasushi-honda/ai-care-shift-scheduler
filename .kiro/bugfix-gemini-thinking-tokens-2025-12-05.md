# BUG-003: Gemini 2.5 Flash æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³å•é¡Œä¿®æ­£è¨˜éŒ²

**ç™ºè¦‹æ—¥**: 2025-12-05
**ä¿®æ­£å®Œäº†æ—¥**: 2025-12-05
**é‡è¦åº¦**: Criticalï¼ˆæœ¬ç•ªç’°å¢ƒã§AIã‚·ãƒ•ãƒˆç”ŸæˆãŒå®Œå…¨ã«å‹•ä½œä¸èƒ½ï¼‰
**å‰æãƒã‚°**: BUG-002ï¼ˆpropertyOrderingè¿½åŠ ï¼‰ä¿®æ­£å¾Œã«ç™ºè¦š

---

## æ¦‚è¦

BUG-002ä¿®æ­£å¾Œã‚‚ã€ŒFailed to parse Gemini JSON response: Unexpected end of JSON inputã€ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã€‚ã—ã‹ã—ä»Šå›ã¯**åŸå› ãŒç•°ãªã‚‹**ã€‚

- **BUG-002**: `propertyOrdering`ãªã—ã§ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹
- **BUG-003**: `MAX_TOKENS`ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™è¶…éï¼‰ã§ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹

## ã‚¨ãƒ©ãƒ¼å†…å®¹

```
âŒ JSON Parse Error: SyntaxError: Unexpected end of JSON input
Response text length: 0
```

**æ–°ã—ã„ãƒ­ã‚°æƒ…å ±**ï¼ˆBUG-002ä¿®æ­£ã§è¿½åŠ ã—ãŸãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã«ã‚ˆã‚Šç™ºè¦‹ï¼‰:
```
ğŸ“Š Vertex AI Response Details: {
  candidatesCount: 1,
  finishReason: 'MAX_TOKENS',  â† é‡è¦ï¼
  usageMetadata: {
    promptTokenCount: 985,
    totalTokenCount: 9176,
    thoughtsTokenCount: 8191  â† æ€è€ƒã«8191ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»
  }
}
```

**ãƒã‚¤ãƒ³ãƒˆ**: `finishReason: 'MAX_TOKENS'` + `thoughtsTokenCount: 8191` â†’ æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ãŒmaxOutputTokens(8192)ã‚’ä½¿ã„åˆ‡ã‚Šã€å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ®‹ã‚‰ãªã‹ã£ãŸ

---

## æ ¹æœ¬åŸå› åˆ†æ

### Gemini 2.5 Flashã€Œæ€è€ƒãƒ¢ãƒ¼ãƒ‰ã€ã®ä»•æ§˜

Gemini 2.5 Flash/Proã«ã¯ã€Œæ€è€ƒãƒ¢ãƒ¼ãƒ‰ï¼ˆThinking Modeï¼‰ã€ãŒå†…è”µã•ã‚Œã¦ãŠã‚Šã€è¤‡é›‘ãªå•é¡Œã‚’æ®µéšçš„ã«æ¨è«–ã™ã‚‹ã€‚

**å•é¡Œç‚¹**:
- æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ`thoughtsTokenCount`ï¼‰ã¯`maxOutputTokens`ã®äºˆç®—ã‹ã‚‰æ¶ˆè²»ã•ã‚Œã‚‹
- æ€è€ƒã«å¤šãã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã†ã¨ã€å®Ÿéš›ã®å‡ºåŠ›ã«ä½¿ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸è¶³
- `thoughtsTokenCount + outputTokenCount > maxOutputTokens`ã®å ´åˆã€`finishReason: 'MAX_TOKENS'`ã§ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹

### æ—¢çŸ¥ã®å•é¡Œï¼ˆå¤–éƒ¨å ±å‘Šï¼‰

[googleapis/python-genai Issue #782](https://github.com/googleapis/python-genai/issues/782):
> "If MAX_TOKENS finish reason is triggered, the response text is empty, making debugging very difficult."

---

## ä¿®æ­£å†…å®¹

### ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«

1. `functions/src/phased-generation.ts`
2. `functions/src/shift-generation.ts`

### ä¿®æ­£å†…å®¹

```typescript
// Before
maxOutputTokens: 8192,

// After
maxOutputTokens: 65536,  // Gemini 2.5 Flash thinking mode uses tokens from this budget
```

**å¤‰æ›´ç®‡æ‰€**: 3ç®‡æ‰€ï¼ˆphased-generation.ts: 2ç®‡æ‰€ã€shift-generation.ts: 1ç®‡æ‰€ï¼‰

### ãªãœ65536ã‹

- Gemini 2.5 Flashã®æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: 65,536ï¼ˆasia-northeast1ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
- æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ~8,000-16,000ï¼‰+ å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ~4,000-8,000ï¼‰ã‚’ååˆ†ã«ã‚«ãƒãƒ¼
- ã‚³ã‚¹ãƒˆå½±éŸ¿: å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³å˜ä¾¡ã¯å¤‰ã‚ã‚‰ãªã„ãŸã‚ã€å®Ÿéš›ã«ä½¿ç”¨ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®ã¿èª²é‡‘

---

## èª¿æŸ»ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‰ãƒªãƒ–ãƒ³ï¼‰

### Step 1: Cloud Functionsãƒ­ã‚°ç¢ºèª

```bash
gcloud functions logs read generateShift --region=asia-northeast1 --project=ai-care-shift-scheduler --limit=30
```

çµæœ:
- `finishReason: 'MAX_TOKENS'` ã‚’ç™ºè¦‹
- `thoughtsTokenCount: 8191` ã‚’ç™ºè¦‹

### Step 2: BUG-002ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®åŠ¹æœ

BUG-002ä¿®æ­£æ™‚ã«è¿½åŠ ã—ãŸãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã«ã‚ˆã‚Šã€ä»Šå›ã®å•é¡Œã‚’å³åº§ã«ç‰¹å®šã§ããŸï¼š
```typescript
console.log('ğŸ“Š Vertex AI Response Details:', {
  finishReason: candidate?.finishReason || 'N/A',
  usageMetadata: response.usageMetadata || {},
});
```

### Step 3: Webæ¤œç´¢ã«ã‚ˆã‚‹è£ä»˜ã‘

- [googleapis/python-genai Issue #782](https://github.com/googleapis/python-genai/issues/782)
- [Google AI Developers Forum: max_output_tokens isn't respected](https://discuss.ai.google.dev/t/max-output-tokens-isnt-respected-when-using-gemini-2-5-flash-model/106708)

---

## BUG-001/002/003ã®é–¢é€£

```
BUG-001: CORSã‚¨ãƒ©ãƒ¼
  â†“ ä¿®æ­£å¾Œ
BUG-002: propertyOrderingãªã—ã§ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹
  â†“ ä¿®æ­£å¾Œï¼ˆ+ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ ï¼‰
BUG-003: MAX_TOKENSã§ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹ â† ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®ãŠã‹ã’ã§å³ç‰¹å®š
```

**æ•™è¨“**: é©åˆ‡ãªãƒ­ã‚°ã‚’æ®‹ã™ã“ã¨ã§ã€æ¬¡ã®å•é¡Œç™ºè¦‹ãŒæ ¼æ®µã«æ—©ããªã‚‹

---

## æŠ€è¡“çš„è©³ç´°

### Gemini 2.5 Flash æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã®ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»

| ã‚«ãƒ†ã‚´ãƒª | ä»Šå›ã®ã‚±ãƒ¼ã‚¹ |
|---------|-------------|
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ | 985 |
| æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ | 8,191 |
| å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | 0ï¼ˆä¸è¶³ï¼‰ |
| åˆè¨ˆ | 9,176 |
| maxOutputTokensè¨­å®š | 8,192 |
| çµæœ | MAX_TOKENS + ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹ |

### ä¿®æ­£å¾Œã®äºˆæƒ³

| ã‚«ãƒ†ã‚´ãƒª | äºˆæƒ³ |
|---------|------|
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ | ~1,000 |
| æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ | ~8,000-16,000 |
| å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ | ~4,000-8,000 |
| åˆè¨ˆ | ~13,000-25,000 |
| maxOutputTokensè¨­å®š | 65,536 |
| çµæœ | æ­£å¸¸å®Œäº† |

---

## å†ç™ºé˜²æ­¢ç­–

### 1. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

ä»¥ä¸‹ã®æŒ‡æ¨™ã‚’ç›£è¦–ï¼š
- `finishReason`: `STOP`ä»¥å¤–ï¼ˆç‰¹ã«`MAX_TOKENS`ï¼‰ã¯è­¦å‘Š
- `thoughtsTokenCount`: æ€¥å¢—ã—ã¦ã„ã‚‹å ´åˆã¯èª¿æŸ»

### 2. è¨­å®šãƒ«ãƒ¼ãƒ«ï¼ˆCLAUDE.mdæ›´æ–°ï¼‰

```
maxOutputTokens: 65536  // Gemini 2.5 Flashæ€è€ƒãƒ¢ãƒ¼ãƒ‰å¯¾å¿œ
```

---

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [BUG-001ä¿®æ­£è¨˜éŒ²](bugfix-cors-cloud-functions-2025-12-05.md) - CORSã‚¨ãƒ©ãƒ¼
- [BUG-002ä¿®æ­£è¨˜éŒ²](bugfix-gemini-empty-response-2025-12-05.md) - propertyOrdering
- [gemini_region_critical_rule](.serena/memories/gemini_region_critical_rule.md) - ãƒªãƒ¼ã‚¸ãƒ§ãƒ³è¨­å®šãƒ«ãƒ¼ãƒ«

---

## å­¦ã³ãƒ»æ•™è¨“

1. **ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã®ä¾¡å€¤**: BUG-002ã§è¿½åŠ ã—ãŸãƒ­ã‚°ãŒBUG-003ã®å³æ™‚ç™ºè¦‹ã«è²¢çŒ®
2. **Gemini 2.5ã®æ–°æ©Ÿèƒ½ã«æ³¨æ„**: æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã¯å¼·åŠ›ã ãŒã€ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã«å½±éŸ¿
3. **ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã¯è¤‡æ•°ã®åŸå› **: `responseLength: 0`ã ã‘ã§ã¯åŸå› ç‰¹å®šä¸å¯ã€`finishReason`ç¢ºèªãŒå¿…é ˆ
4. **ä½™è£•ã‚’æŒã£ãŸè¨­å®š**: ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã¯ä½™è£•ã‚’æŒã£ã¦è¨­å®šï¼ˆ8192 â†’ 65536ï¼‰

---

## ä¿®æ­£ã‚³ãƒŸãƒƒãƒˆ

```
fix(BUG-003): increase maxOutputTokens for Gemini 2.5 Flash thinking mode

- Increase maxOutputTokens from 8192 to 65536
- Gemini 2.5 Flash uses thinking tokens from this budget
- When thoughtsTokenCount exceeds budget, response text is empty
- Reference: googleapis/python-genai#782
```
